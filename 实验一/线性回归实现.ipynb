{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Tensor和autograd来实现一个线性回归，具体的步骤有：\n",
    "* 生成和读取数据集\n",
    "* 构建模型\n",
    "* 初始化模型参数\n",
    "* 定义损失函数和优化算法\n",
    "* 训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入本次实验所需的包或模块，其中matplotlib包可用于作图，用来显示生成的数据的二维图。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本实验先构造一个简单训练数据集，通过这个数据集可以直观的比较模型训练出来的参数和真实的模型参数的区别。设训练数据集样本数为1000，输入个数（特征数）为2，给定随机生成的批量样本特征X∈R^1000×2。这里使用线性回归模型的真实权重w=[2，-3.4].T和偏差b=4.2，以及一个随机噪声项e来生成标签。  \n",
    "  \n",
    "### y=xw.T+b+e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其中，噪声项e是服从均值0、标准差为0.01的正态分布。噪声代表了数据中无意义的干扰。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "num_examples = 1000\n",
    "true_w = [2,-3.4]\n",
    "true_b = 4.2\n",
    "features = torch.tensor(np.random.normal(0,1,(num_examples,num_inputs)),dtype=torch.float)\n",
    "labels = true_w[0]*features[:,0]+true_w[1]*features[:,1]+true_b\n",
    "labels += torch.tensor(np.random.normal(0,0.01,size=labels.size()),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1fb56a1f080>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(3.5,2.5))\n",
    "plt.xlim(-4,4)\n",
    "plt.ylim(-10,20)\n",
    "plt.scatter(features[:,1].numpy(),labels.numpy(),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在模型训练的时候，需要遍历数据集并不断读取下批量的数据样本。这里本实验定义一个函数`data_iter()` 它每次返回batch_size（批量大小）个随机样本的特征与标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 2\n",
    "def data_iter(batch_size,features,labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices) #样本的读取顺序是随机的\n",
    "    for i in range(0,num_examples,batch_size):\n",
    "#         print(i)\n",
    "        j = torch.LongTensor(indices[i:min(i+batch_size,num_examples)])# 最后一次可能不足一个batch\n",
    "        yield features.index_select(0,j),labels.index_select(0,j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在构建模型之前，需要将权重和偏置初始化。本实验将权重初始化成均值为0、标准差为0.01的正态随机数，偏置初始化为0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor(np.random.normal(0,0.01,(num_inputs,1)),dtype=torch.float32)\n",
    "b = torch.zeros(1,dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在后面的模型训练中，需要对这些参数求梯度来迭代参数的值，  \n",
    "### 因此要设置requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面使用mm()函数做矩阵乘法，来实现线性回归的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linreg(X,w,b):\n",
    "    return torch.mm(X,w)+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 损失函数和优化算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 本实验使用平方损失来定义线性回归的损失函数。在实现中，我们需要把真实值y变形成预测值y_hat形状。以下的函数返回的结果和y_hat的形状相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squared_loss(y_hat,y):\n",
    "    return (y_hat-y.view(y_hat.size()))**2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以下的sgd函数实现了小批量随机梯度下降算法。它通过不断迭代模型参数来优化损失函数。这里自动求梯度模块计算得到的是一个批量样本的梯度和。我们将它除以批量大小来得到平均值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params,lr,batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr*param.grad/batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 手动实现线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在训练过程中，模型将会多次迭代更新参数。在每次迭代中，根据当前读取的小批量数据样本（特征x和标签y），通过调用反向函数backward计算小批量随机梯度，并调用优化算法sgd迭代模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,loss0.015693\n",
      "epoch2,loss0.008332\n",
      "epoch3,loss0.004437\n",
      "epoch4,loss0.002374\n",
      "epoch5,loss0.001281\n",
      "epoch6,loss0.000702\n",
      "epoch7,loss0.000395\n",
      "epoch8,loss0.000233\n",
      "epoch9,loss0.000146\n",
      "epoch10,loss0.000100\n"
     ]
    }
   ],
   "source": [
    "lr = 0.03\n",
    "num_epochs = 10\n",
    "net = linreg\n",
    "loss = squared_loss\n",
    "batch_size = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for X,y in data_iter(batch_size,features,labels):\n",
    "        l = loss(net(X,w,b),y).sum()\n",
    "        l.backward()\n",
    "        sgd([w,b],lr,batch_size)\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    train_l = loss(net(features,w,b),labels)\n",
    "    print('epoch%d,loss%f'%(epoch+1,train_l.mean().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, -3.4] \n",
      " tensor([[ 1.9982],\n",
      "        [-3.3937]], requires_grad=True)\n",
      "4.2 \n",
      " tensor([4.1927], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(true_w,'\\n',w)\n",
    "print(true_b,'\\n',b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 利用torch.nn实现线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* PyTorch提供了data库来读取数据。由于data常用作变量名，这里将导入的data模块用Data代替。对前面的读取数据部分可以使用data库来处理。在每一次迭代中，使用Data随机读取包含10个数据样本的小批量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as Data\n",
    "batch_size = 100\n",
    "lr = 0.3\n",
    "# 将训练数据的特征和标签组合\n",
    "dataset = Data.TensorDataset(features,labels)\n",
    "\n",
    "# 把dataset放入DataLoader\n",
    "data_iter = Data.DataLoader(\n",
    "            dataset = dataset,\n",
    "            batch_size = batch_size,\n",
    "            shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 构建模型的过程中，最常见的方法就是继承nn.Module，然后构建自己的网络。一个nn.Module实例需要包含一些层以及返回输出的前向传播方法。下面利用nn.Module构建一个线性回归模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class LinearNet(nn.Module):\n",
    "    def __init__(self,n_feature):\n",
    "        super(LinearNet,self).__init__()\n",
    "        self.linear = nn.Linear(n_feature,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y = self.linear(x)\n",
    "        return y\n",
    "    \n",
    "net = LinearNet(num_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型参数初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在使用定义的模型net之前，需要对模型中的一些参数进行初始化。Pytorch在init模块中提供了许多初始化参数的方法。我们可以调用init.normal模块通过正态分布对线性回归中的权重和偏差进行初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn import init\n",
    "\n",
    "init.normal_(net.linear.weight,mean=0,std=0.01)\n",
    "init.constant_(net.linear.bias,val=0) #也可以直接修改bias的data：net[0].bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数和优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pytorch在torch.nn中提供了各种损失函数，这些损失函数实现为nn.Module的子类，可以将这些损失函数作为一种特殊的层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pytorch在torch.optim模块中提供了诸如SGD，Adam和RMSProop等优化算法。本例将使用小批量随机梯度下降算法进行优化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.SGD(net.parameters(),lr=0.03)\n",
    "\n",
    "# 可以为不同的子网络设置不同学习率\n",
    "# optimizer = optim.SGD([\n",
    "#     # 如果不指定学习率，则会默认使用最外层学习率\n",
    "#     {'params': net.subnet1.parameters()}\n",
    "#     {'params': net.subnet2.parameters(),'lr':0.01}\n",
    "# ],lr=0.03)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 训练模型时，可以调用optim中的step()函数来迭代模型参数。按照小批量随机梯度下降的定义，在step()函数中指定批量大小，从而对批量中的样本梯度求平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1,loss: 0.000083\n",
      "epoch 2,loss: 0.000090\n",
      "epoch 3,loss: 0.000082\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(1,num_epochs+1):\n",
    "    for X,y in data_iter:\n",
    "        output = net(X)\n",
    "        l = loss(output,y.view(-1,1))\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    print('epoch %d,loss: %f'%(epoch,l.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型预测及评价（分类问题）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 对于分类问题，给定任一样本特征，模型可以预测每个输出类别的概率。通常，我们把预测概率最大的类别作为输出类别。如果它与真实类别(标签)一致，说明这次预测时正确的。我们使用准确率(accuracy)来评价模型的表现。它等于正确实现预测数量与总预测数量之比。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 下面我们给出准确率计算函数的实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    return (y_hat.argmax(dim=1)==y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 评价模型net在数据集data_itear上的准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter,net):\n",
    "    acc_sum,n = 0.0,0\n",
    "    for X,y in data_iter:\n",
    "        acc_sum += (net(X).argmax(dim=1)==y).float().sum().item()\n",
    "        n += y.shape[0]\n",
    "    return acc_sum/n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
